{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Hdla4StSZ80F",
        "outputId": "b60f124a-d6dc-409f-c921-0c63315d7424"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.3)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.3.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254,
          "referenced_widgets": [
            "5d07faecab514de58093a00b1283214e",
            "1610f24da5104f2f857e4332f52b9d3c",
            "cb0c8991451844b0b466bec2ee65ced6",
            "a06ce5768efd4a61b28f1bdecf2d02ee",
            "566bcb4ab805428f86865109aa76c8b8",
            "917e8d391ef146a089d32b10df5bb600",
            "bbb14285aeff4646a391bd7646dce819",
            "c799f91a75614f79aca17a2f508b8ca3",
            "e26d77d065404ec6b6568a84d4a630d0",
            "834286e3664544898072ab3d326e0ba3",
            "5b89d18a743a472b9b0ece53021f7f57",
            "d4751ad22b714a13b8f70b2071593a84",
            "add3d7461a3a46c2aac89a51d67188ee",
            "1d492a6e410d470eac4b1269bce93fe8",
            "62d3bf940a05485ea966fd765ddabce6",
            "91ac5e9239ea4c8f954bf93f2979ca77",
            "aaf3f0fb4fcc4a3883071d4bd3aae07e",
            "06b094511ace44618116bac1ca307974",
            "aa833daf43bb460093c15521685e8d1b",
            "ac7476fc6999438aba6bbca87d12c7c6",
            "85d93db47ef345508cfa22f6cba16fdb",
            "ed818298e7c14fe8a313be3e4135e550",
            "9bb77d232f704c5cb36aab6ad9cff7b2",
            "f6376ee8707f49068ca4b074afb7bb3d",
            "2e523fe12bd44f3d8903e4dd646c1569",
            "c72a49a3ef724bd081cccaf98d7c2690",
            "e79a9eaa7f754f93888580f2bebc9bc7",
            "f148411ec5c74574930c49713f2baff5",
            "27fd9a6e39b54b7db629421b24ea00b5",
            "a81fd3d848364f52b903917aa93f275e",
            "acdc9619c2b048acb9c9a5512949aaaa",
            "8dde0694f6624a7b9140209bf51a7ac2",
            "977def161d9f43848751eec705ec30ec",
            "6be2296086644522933a16603ba49885",
            "a1ffb4a8b07b4133be006aef543b2d2d",
            "40567f0c648c42c3b4d692359d9826b2",
            "731c30d8d403414687aa664a8b731a56",
            "745cc22ecaa74b93b390f090dc86ecec",
            "d8726fa5eadd4d7bb0af062cb3133a0d",
            "606efc36938d409f85108c44bece1651",
            "42a3b49e3b4243c4a987399a18dafdab",
            "e71e90cde42e44d4b1e72537b9978d40",
            "01e7d2f491ba4acba4f8fa1d5331ad90",
            "17ff874930dc4a2a981775e5fe25dd45"
          ]
        },
        "id": "yI2luyjYacQ8",
        "outputId": "43bb25d7-3037-48cb-d11a-40900ef9528e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d07faecab514de58093a00b1283214e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/18.5k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d4751ad22b714a13b8f70b2071593a84",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "bookcorpus.py:   0%|          | 0.00/3.25k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9bb77d232f704c5cb36aab6ad9cff7b2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/1.18G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6be2296086644522933a16603ba49885",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/74004228 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset=load_dataset(\"bookcorpus\",trust_remote_code=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3xVz2KWgJYw",
        "outputId": "03fe29d8-94ac-46ae-830d-35a508439fed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'text': \"each time she looked into mason 's face , she was grateful that he looked nothing like his father .\"}\n",
            "74004228\n"
          ]
        }
      ],
      "source": [
        "train_data = dataset[\"train\"]\n",
        "\n",
        "# Peek into the data\n",
        "print(train_data[10])\n",
        "df=len(train_data)\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "a3e583c42ffa49e594d72e9f0c6cd58f",
            "71eb40a7d854442dab53c9d1a365c58b",
            "4ecf3e5ffa1147b9b6d560470e16f034",
            "4714ebaceaba419fa61d6d04a32bec27",
            "7778313ea3a34853891a9b4fa9885230",
            "42ef0f53040f4d9db5a1ae10787b8ad8",
            "d75f377728e74a81bac661244d70d45e",
            "55aeb952bb22444aaaae32d675e4fa48",
            "20182bdb4b794e9ba5dfd75c3e11b84b",
            "3263ebba37d349c58db2b9540b66b2e3",
            "6c4e75bf4ae7470789436fc00ef50d78",
            "fa03145bb726483394d7cf2ea0a03486",
            "67a7cf78b8b141209a2fc7abb9856811",
            "f5cfdd2d9759467fa1150ebf45a2b7ad",
            "097d357585b844558dcaf72c32c35a49",
            "5d914b8518a74a86a3ff85b143673742",
            "9c451e8338dd4ceabb206276ffc41d36",
            "30b387fd58934ae3bd27403e1cf1df7a",
            "1646c25c126a41cf8d74265c743b9c53",
            "01e5eef4b2f34ceaac9f356cf22af31c",
            "feb0348091444112ad9433714401911e",
            "488567b2ca9f4e98a2ee1f3a5d2dd371",
            "785c3311dbf742a8873322a473b25ce0",
            "d54edfc796974f26ae10a41869f783f3",
            "9c7f9dcebe854543a10a5e82e01b719e",
            "f088719019774a94be48408673c994aa",
            "60f4eacee1fe484192d8da0ba28f1826",
            "8610a8eee2fb4eb0aaa5dd4e4a9bef2e",
            "2ae9c4ec76d5425ca9bcc3e0e5559d92",
            "93a01f9090814ce59fd3b05ff1cc3cd2",
            "53efeb1b4810415ab4326bde56469ea5",
            "9d83c45783d94da9bb43610d7025af92",
            "dd6c8df10bd24fbb9d8491a3912fd864",
            "e589fe9898d3408d9dbdba3a1e215e0f",
            "41855fb4542f4f368014c4d7a99cb687",
            "4c1142b87cdc4d518ef74ae5ab26bfd6",
            "03ab083b042b427091b69c8b9889a924",
            "d5a4802694d345a58793d422e7bc740c",
            "62155e7d6ce44851b7d161ec56fd071e",
            "ab50118e5cc94124974ea21ab583a9b8",
            "420eb6668c6d4460acf6d85742124cf9",
            "6d045b5328f94ed3be2b2e77816f06ce",
            "24f4379e5d1540b1889bb23748f1a874",
            "830fee12c44f446c86e437cdc9e13bd5",
            "b7bc43ab57984dc68654b0a0ea7f956f",
            "687c49e7499d455a972a503f426ed717",
            "f89668b607cb4ca282d70be75b15497d",
            "200a30055ed54e4e8d3f6a2e8d1938e6",
            "7793f242bcc7435c85b79eafe3852bb5",
            "3653feae8e4247158a0dbf7182b37fc4",
            "eac45ce9697e4ebfb9a3d48cf0732574",
            "11e05e9f80374c109a6e0ee7c44040de",
            "3297eb585a564902859f57624907043c",
            "70a7b9903280472fbd9b972a15417c04",
            "39731b3452414df5a588a36016d66a6b"
          ]
        },
        "id": "dQTGv2EDad3i",
        "outputId": "a2276ac6-ed20-447e-cfda-4e154fd39d55"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a3e583c42ffa49e594d72e9f0c6cd58f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa03145bb726483394d7cf2ea0a03486",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "785c3311dbf742a8873322a473b25ce0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e589fe9898d3408d9dbdba3a1e215e0f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b7bc43ab57984dc68654b0a0ea7f956f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer=AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "def tokenized_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    dataset=tokenized_datasets = dataset.map(tokenized_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBavdxfAaemD"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "data_collatr=DataCollatorForLanguageModeling(tokenizer=tokenizer,mlm=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137,
          "referenced_widgets": [
            "dec9ca2951744ed3870bade88cfd542e",
            "40bd091d19a94cfbb87601f1259f9264",
            "b3ce704fe1b3494c86d36f405a9f4472",
            "0da93316b4684b1b89e62a6d39fac438",
            "c5c4a6a0c46d41c3b795fce3df8debd7",
            "52a6d86a9e9d4852b3dff845bf7526de",
            "ea44635f9c1a4961a6a56943089def0c",
            "326f3f41b43f4179af218085208a1824",
            "a9d4c2dbcf43404cbcc5e80c731cc202",
            "f55e1571cec649ffbb04957870cfa9da",
            "b97c74b295c64f6b9ad410e82f3cb904",
            "0e43e0a08ab64784a401a96d57f2068e",
            "823faff3d4fc49b7977db86de9cac272",
            "20ceac6d91b346e8a40217cc1038ec71",
            "91fd917ec70a4473ab7da3ec516b2490",
            "ba514bee29a141078cd35aa3204b7c75",
            "a4ba8b11e7264fcdb5fe9489f19de9da",
            "73afbaf6f2fc4e91bb4fbf3a457a9b16",
            "bd237b50b5b54cc9857fd18661f8815c",
            "4655e4282a9b4fe5b2ef108044074f73",
            "3fed145ff5344227801a27b561a89bb3",
            "83c93b0dc2f34341ae59261e229950b9"
          ]
        },
        "id": "siJs35lUonKK",
        "outputId": "b4fcef98-4e21-408e-c135-c7fd9309f457"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dec9ca2951744ed3870bade88cfd542e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0e43e0a08ab64784a401a96d57f2068e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import Trainer, TrainingArguments, AutoModelForCausalLM\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./gpt2-bookcorpus\",\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        ")\n",
        "\n",
        "trainer.save_model(\"./gpt2-bookcorpus\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJZF81y6pTAe"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "trainer.save_model(\"./gpt2-bookcorpus\")\n",
        "tokenizer.save_pretrained(\"./gpt2-bookcorpus\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"./gpt2-bookcorpus\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"./gpt2-bookcorpus\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RuNsLc9opC-5"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "\n",
        "model_path = \"./gpt2-bookcorpus\"\n",
        "\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLnHLmfLfm4Z",
        "outputId": "e11d4a4d-d843-4823-9928-f90b5d3abc0c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "generated_text = generator(\" \", max_length=50)[0]['generated_text']\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "maaOScv9fm18",
        "outputId": "f2491c30-c4f4-4bd2-b3fb-cea3bae86ce0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'sachin is the god of cricket he is the most popular cricketer in the world, but that has nothing to do with who I play for.\\n\\nWhat matters is that you need the right man and the right equipment so that you can get your game to a certain threshold. Most players need the right gear and the right gear. All that is required is a good, experienced coach.\\n\\nBarry Dickson has worked hard at his craft with both men and is very open to discussions and suggestions on issues of his own. His opinions often come to him and he would know a lot about the sport and the sport is being dealt a serious injury. We will be doing a bit more digging into those thoughts and I believe that the time to start a conversation is long overdue.\\n\\nIn our new home in the south of England there are numerous areas of interest including:\\n\\nWe are in the area which is a small town with very significant, well-developed communities.'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generator(\"sachin is the god of cricket he is the most popular cricketer in the world,\", max_length=200)[0]['generated_text']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "PGeTW3Y5tFyi",
        "outputId": "0f3ffc17-36ec-43ba-8831-76bcae92eb94"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Nagarkurnool is a town in the Indian state of Telangana known for its beautiful landscapes and agricultural activities. The town is famous for...'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generator(\"Nagarkurnool is a town in the Indian state of Telangana known for its beautiful landscapes and agricultural activities. The town is famous for...\", max_length=100)[0]['generated_text']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z57Dav_iuT7Y"
      },
      "source": [
        "TO OVERCOME THIS SITUATION WE USE RAG ( RETRIEVAL AUGMENTED GENERATION)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dm4V_l2Ac9iH"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "import requests\n",
        "\n",
        "def web_search(query):\n",
        "    api_key = \"6fbc8886f9824fda838c9179b17ac3f1a3d3fcbd7d18caeefed03e61fc756cba\"  # Replace with your SerpAPI key\n",
        "    search_url = f\"https://serpapi.com/search.json?q={query}&api_key={api_key}\"\n",
        "\n",
        "    response = requests.get(search_url)\n",
        "    search_results = response.json()\n",
        "\n",
        "    return search_results[\"organic_results\"]  # Get organic search results (you can also use ads, etc.)\n",
        "    search_results = response.json()\n",
        "\n",
        "    return search_results[\"organic_results\"]  # Get organic search results (you can also use ads, etc.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LR8PNuZWdRfu"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Initialize tokenizer (using a pre-trained model like GPT-2 or T5)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "def tokenize_search_results(search_results):\n",
        "    # Combine search results into a single text\n",
        "    results_text = \" \".join([result['snippet'] for result in search_results])\n",
        "\n",
        "    # Tokenize the combined search results text\n",
        "    tokenized_results = tokenizer(results_text, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "    return tokenized_results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc2EicmOdTN6",
        "outputId": "8b572aad-9059-4ceb-a065-e88cbc84729b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, pipeline\n",
        "\n",
        "# Load the pre-trained model for text generation (GPT-2 or any other model)\n",
        "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
        "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "def generate_response(query, search_results,**kwargs):\n",
        "    # Tokenize both the query and the search results\n",
        "    query_tokens = tokenizer(query, return_tensors=\"pt\")\n",
        "    search_tokens = tokenize_search_results(search_results)\n",
        "\n",
        "    # Combine query and search results for generation\n",
        "    input_ids = query_tokens['input_ids']\n",
        "    attention_mask = query_tokens['attention_mask']\n",
        "    context_ids = search_tokens['input_ids']\n",
        "    context_mask = search_tokens['attention_mask']\n",
        "\n",
        "    # Generate text using the combined input (query + search results)\n",
        "    input_combined = torch.cat([input_ids, context_ids], dim=1)\n",
        "    attention_combined = torch.cat([attention_mask, context_mask], dim=1)\n",
        "\n",
        "    output = model.generate(input_combined, attention_mask=attention_combined,**kwargs)\n",
        "\n",
        "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    return generated_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEaTx33tdU_Z"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "def rag_system(query,**kwargs):\n",
        "\n",
        "    # Step 1: Get web search results\n",
        "    search_results = web_search(query)\n",
        "\n",
        "    # Step 2: Generate response using the search results and the original query\n",
        "    response = generate_response(query, search_results,**kwargs)\n",
        "\n",
        "    return response\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJsl_bewdYy9",
        "outputId": "0225221e-921f-46c4-a856-dc6ae7c123b6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What is Nagarkurnool known for?Tourism · Umamaheshwaram · Saleswaram · Lalitha Someswara Swamy Temple · Sri Madanagopalaswamy Temple · Lakshmi Narasimhaswamy Temple · Nandeeswara shaneeswara ... The district is also home to highly popular and truly exotic eco-tourism destination called Somasila, located near Kollapur. It is located close to the ... Nagarkurnool is a town and is the district headquarters of Nagarkurnool district of the Indian state of Telangana. It is located at nearly 120 km from the ... Until 120 years ago, Nagarkurnool was a main junction for transport and district headquarters for most of the south Telangana region. Farmers traveling in this ... Nagarkurnool is believed to have been named after the two kings called Nagana and Kandana, who were brothers too. The district, today has three revenue ... Welcome to Nagarkurnool: Where History and Nature Collide · Mallela Theertham Waterfall: Nature's Shower · Sri Lalitha Someswara Swamy Temple: A ... The hidden jewel among Telangana's tourism destinations us Nagarkurnool. With its picturesque villages, peaceful waterfalls, and historic temples, this ... The Nagarjunasagar-Srisailam Tiger Reserve also serves as one of the popular wildlife sanctuaries in the country. MallelaTheertham waterfall, one of the most ... Nagarkurnool District Tourism: Tripadvisor has 19 reviews of Nagarkurnool District Hotels, Attractions, and Restaurants making it your best Nagarkurnool Top 10 best places to visit in Nagarkurnool | NagarKurnool ... Uma Maheswaram Temple History Achampet | Nallamala | Telugu Unknown Facts | SumanTV ... Nagarkurnool is a city of over 1,000 people located in the state of Telangana. It is also known as the capital of the state of Telangana. It is also known as the capital of the state of Telangana. It is also known as the capital of the state of Telangana. It is also known as the capital of the state of Telangana. It is also known as the capital of the state of Telangana. It is also known as the capital of the state of Telang\n"
          ]
        }
      ],
      "source": [
        "query = \"What is Nagarkurnool known for?\"\n",
        "response = rag_system(query)\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nkzw8yFvnIxJ",
        "outputId": "c1cdb4f6-4cb7-4eb2-d556-557c63e45533"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Only give me the temperature in °C and condition for NagarkurnoolBe prepared with the most accurate 10-day forecast for Nagarkurnool ... Low 24°C. Winds SE at 10 to 15 km/h. Humidity65%. UV Index0 of 11. Moonrise12 ... Nagarkurnool, Telangana, India Weather Forecast, with current conditions, wind, air quality, and what to expect for the next 3 days. Tue 01 | Night ... Mostly clear. Hazy. Low around 70F. Winds E at 10 to 15 mph. Humidity64%. Nagarkurnool Mandal, Telangana, India 10-Day Weather Forecaststar_ratehome ; Pressure. 29.74 · in ; Visibility. 9 · miles ; Dew Point. 65 · F ; Humidity. 58 · %. Beach & Pool · Poor. Conditions for a day at the beach or pool are poor. · Fair. Conditions for a day at the beach or pool are fair. · Good. Conditions for a day ... Nagarkurnool Weather · Today April 11. Light rain. 30% 0.004 in. 99° / 76° · Tomorrow April 12. Scattered clouds. 101° / 74°. Calm · Sunday April 13. Sunny. 101° / ... Partly cloudy skies this evening will give way to occasional showers overnight. Hazy. Low around 75F. Winds SE at 5 to 10 mph. Chance of rain 50%. icon. Local Weather Report and Forecast For: NAGARKURNOOL Dated :Apr 13, 2025. NAGARKURNOOL. 7 Day's Forecast. Date, Min Temp, Max Temp, Weather. 13-Apr, 26.9, 38.7 ... I'm T. Balaji. Weather enthusiast & Btech Civil 4th year student in JNTUH HYD. Follow me for weather updates of Telangana. Not affiliated to any official ... This afternoon in Nagarkurnool, Cloud and long sunny periods. No precipitation. Temperatures will vary between 28 and 38°C. The reliability of the situation ... The weather forecast is based on the latest data from the National Weather Service. The forecast is based on\n"
          ]
        }
      ],
      "source": [
        "query = \"Only give me the temperature in °C and condition for Nagarkurnool\"\n",
        "max_new_tokens=20\n",
        "response = rag_system(query)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcmAz_bTpWO6",
        "outputId": "5781c874-83ff-4fe2-a3c8-e671344fa690"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "what is mean by puchakayaThe word or phrase పుచ్చకాయ refers to large oblong or roundish melon with a hard green rind and sweet watery red or occasionally yellowish pulp, or an African ... It is called “puchchakAya” giving the meaning “an edible fruit that looks like a small human head and retains outer peel colour as of a “kAya-unripe fruit” ... The word or phrase puchchakaaya refers to . See puchchakaaya meaning in English, puchchakaaya definition, translation and meaning of puchchakaaya in English. Its named puchakaya after mabbu sale. Gaddamleni magesh babu. Also mean kojja · You are a puchakaya. You can find puchakaya in railway stations. watermelon is the translation of \"పుచ్చకాయ\" into English. Sample translated sentence: స్పెయిన్ దేశస్థులు సహితం ఈ హోర్చాటా పానీయాన్ని బాదం, గుమ్మడి లేక పుచ్చకాయ విత్తనాలతోను, మరియు బియ్యం, జల్దరు పండ్లు, ఆపిల్ ... Watermelon (Citrullus lanatus) is a flowering plant species of the Cucurbitaceae family and the name of its edible fruit. Nutrient-Rich: Watermelon seeds are enriched with essential nutrients like protein, healthy fats, and minerals, our Watermelon Seeds provide a nourishing boost to your diet. @salserorunner：The word púchica in Guatemala has so many uses. It also denotes someone's excitement. For example: Púchica vos, qué buena onda! CHILLATAI. Hybrid Water Melon Seed / Puchakaya Seeds / Tharboosani Seed (20 per packet) · Seed Type: Fruit · Suitable For: Outdoor · Organic Plant Seed · Seed For: ... Learn the fascinating origin of the Puchakaya surname; its meaning & distribution. Unlock your family history in the largest database of last names.\n",
            "\n",
            "Puchakaya is a fruit that is found in many tropical regions of the world.\n"
          ]
        }
      ],
      "source": [
        "query=\"what is mean by puchakaya\"\n",
        "response=rag_system(query)\n",
        "print(response)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
